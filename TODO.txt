
DONE
- Sleep primitive
- ensure context is passed through layers (when appropriate)
- Log timestamps need milliseconds
- Single log file per session (may include multiple pipelines)


TODO
- how do we handle failure? Return error? Raise failed event?
- Prevent infinite retries on error
- Support for retries
- rename event package to es or something more generic (it has commands too)
- IDs consistent with SPC format
- Run sub-pipelines
- Improve console output and logging, will make everything easier and more attractive
- Remove (unused) StackID stuff
- Passing output to input
- Stop and resume
- user input primitive
- Test with RedPanda instead of gochannel



TODO
- logging using zap
- work out how to change the topic name to match our format / etc, I think it's related to the cqrs.JSONMarshaller.Name[FromMessage]
- how are events logged into a stream (in order)? can we do middleware or something for that?

NOTES
- Should we capture / load the pipeline definition at the start of the run? What happens if it changes on the way through? We should at least capture the version and then abort if changed?

DECISIONS
- Pipeline definitions and code are not stored in event history, they are referenced
- So, pipeline definitions and code can be updated and will change running pipelines
- But, a pipeline run can choose to pin its version, causing it to abort if an update is completed
- Or, upgrades can choose to pause affected pipeline runs ... queue new runs > finish existing runs > upgrade > restart new runs



DESIGN

Flowpipe runs as a service, and consists of:
* triggers - cron, webhooks, etc to trigger pipeline runs
* pipelines - sets of actions that can be run (manually or by a trigger)

The service has a single process log for everything it is doing. But, each
pipeline run has it's own process (and log). A trigger execution is considered
part of the pipeline run it initiates.


trigger "webhook" "my_webhook" {
    pipeline = pipeline.my_webhook_pipeline
}

trigger "query" "my_query" {
    sql = "select id, title from aws_account"
    pipeline = pipeline.my_account_handler
}

trigger "cron" "my_cron" {
    cron = "* * * * * *"
    pipeline = pipeline.my_scheduled_pipeline
}





timestamp
run_id
pipeline / step being executed
output

[ps_abcd1234] README.md
[ps_abcd1234] test
[ps_abcd1234] foo


[my_pipeline_1.exec_1      ] Command: ls
[my_pipeline_1.exec_1      ] README.md
[my_pipeline_1.exec_1      ] test
[my_pipeline_1.exec_1      ] foo
[my_pipeline_1.sleep_1     ] Sleeping for 5mins...

2023-02-06T11:18:25.364573 [my_pipeline_1.exec_1      ] README.md
2023-02-06T11:18:25.364573 [my_pipeline_1.exec_1      ] test
2023-02-06T11:18:25.364573 [my_pipeline_1.exec_1      ] foo
2023-02-06T11:18:25.364573 [my_pipeline_1.sleep_1     ] Sleeping for 5mins...
2023-02-06T11:18:25.364573 [my_pipeline_1.sleep_1     ] Sleeping for 5mins...